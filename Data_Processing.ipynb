{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44562c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories initialized. Ready to process files from Raw_Data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Define paths based on your structure\n",
    "RAW_DIR = \"Raw_Data\"\n",
    "PROCESSED_DIR = \"Processed_Data\"\n",
    "\n",
    "# Ensure processed directory exists\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Directories initialized. Ready to process files from {RAW_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61380c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014 Processor function defined.\n"
     ]
    }
   ],
   "source": [
    "def process_semeval_2014(folder_name, output_filename):\n",
    "    unified_rows = []\n",
    "    global_idx = 1\n",
    "    \n",
    "    # Target folder: Raw_Data/res_2014\n",
    "    target_path = os.path.join(RAW_DIR, folder_name)\n",
    "    \n",
    "    # We will look for all .xml files in that folder (test, train, val)\n",
    "    files = [f for f in os.listdir(target_path) if f.endswith('.xml')]\n",
    "    \n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(target_path, file_name)\n",
    "        print(f\"Parsing: {file_name}\")\n",
    "        \n",
    "        tree = ET.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        for sentence in root.findall('.//sentence'):\n",
    "            text_node = sentence.find('text')\n",
    "            if text_node is None or text_node.text is None:\n",
    "                continue\n",
    "                \n",
    "            text = text_node.text.strip()\n",
    "            aspect_terms = sentence.find('aspectTerms')\n",
    "            \n",
    "            # If the sentence has aspects, create a row for each\n",
    "            if aspect_terms is not None:\n",
    "                for at in aspect_terms.findall('aspectTerm'):\n",
    "                    unified_rows.append({\n",
    "                        \"sentence_id\": f\"2014_{global_idx:04d}\",\n",
    "                        \"sentence\": text,\n",
    "                        \"aspect\": at.get('term'),\n",
    "                        \"polarity\": at.get('polarity').lower().strip(),\n",
    "                        \"from\": int(at.get('from')),\n",
    "                        \"to\": int(at.get('to'))\n",
    "                    })\n",
    "            \n",
    "            # Increment the ID for every sentence processed\n",
    "            global_idx += 1\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(unified_rows)\n",
    "    \n",
    "    # Save to Processed_Data\n",
    "    final_path = os.path.join(PROCESSED_DIR, output_filename)\n",
    "    df.to_csv(final_path, index=False, encoding='utf-8')\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"2014 Processor function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2d3f8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing: test.xml\n",
      "Parsing: val.xml\n",
      "Parsing: train.xml\n",
      "\n",
      "Processing Complete!\n",
      "Total Rows Extracted: 4923\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>aspect</th>\n",
       "      <th>polarity</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014_0001</td>\n",
       "      <td>The bread is top notch as well.</td>\n",
       "      <td>bread</td>\n",
       "      <td>positive</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014_0002</td>\n",
       "      <td>I have to say they have one of the fastest del...</td>\n",
       "      <td>delivery times</td>\n",
       "      <td>positive</td>\n",
       "      <td>43</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014_0003</td>\n",
       "      <td>Food is always fresh and hot- ready to eat!</td>\n",
       "      <td>Food</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014_0004</td>\n",
       "      <td>Did I mention that the coffee is OUTSTANDING?</td>\n",
       "      <td>coffee</td>\n",
       "      <td>positive</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014_0005</td>\n",
       "      <td>Certainly not the best sushi in New York, howe...</td>\n",
       "      <td>sushi</td>\n",
       "      <td>conflict</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id                                           sentence  \\\n",
       "0   2014_0001                    The bread is top notch as well.   \n",
       "1   2014_0002  I have to say they have one of the fastest del...   \n",
       "2   2014_0003        Food is always fresh and hot- ready to eat!   \n",
       "3   2014_0004      Did I mention that the coffee is OUTSTANDING?   \n",
       "4   2014_0005  Certainly not the best sushi in New York, howe...   \n",
       "\n",
       "           aspect  polarity  from  to  \n",
       "0           bread  positive     4   9  \n",
       "1  delivery times  positive    43  57  \n",
       "2            Food  positive     0   4  \n",
       "3          coffee  positive    23  29  \n",
       "4           sushi  conflict    23  28  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the processor for the res_2014 folder\n",
    "df_2014 = process_semeval_2014(\"res_2014\", \"2014_rest_reviews.csv\")\n",
    "\n",
    "print(f\"\\nProcessing Complete!\")\n",
    "print(f\"Total Rows Extracted: {len(df_2014)}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Display the first 5 rows to check the 'Perfect Number' ID and formatting\n",
    "df_2014.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6347cd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2014 Data Verification ---\n",
      "Total rows (Aspect-level): 4923\n",
      "Unique sentence IDs:       2681\n",
      "Sentences with >1 aspect:  2242\n",
      "Average aspects/sentence:  1.84\n",
      "\n",
      "⚠️ Note: Unique IDs and unique text counts differ.\n",
      "This usually happens if the exact same sentence appears twice in different files.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to the file we just created\n",
    "file_path = os.path.join(\"Processed_Data\", \"2014_rest_reviews.csv\")\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    total_rows = len(df)\n",
    "    unique_ids = df['sentence_id'].nunique()\n",
    "    multi_aspect_count = total_rows - unique_ids\n",
    "    \n",
    "    print(\"--- 2014 Data Verification ---\")\n",
    "    print(f\"Total rows (Aspect-level): {total_rows}\")\n",
    "    print(f\"Unique sentence IDs:       {unique_ids}\")\n",
    "    print(f\"Sentences with >1 aspect:  {multi_aspect_count}\")\n",
    "    \n",
    "    # Calculate average aspects per sentence for analysis\n",
    "    avg_aspects = total_rows / unique_ids\n",
    "    print(f\"Average aspects/sentence:  {avg_aspects:.2f}\")\n",
    "    \n",
    "    # Verify that IDs are consistent with the text\n",
    "    unique_text = df['sentence'].nunique()\n",
    "    if unique_ids == unique_text:\n",
    "        print(\"\\n✅ Verification Passed: Each unique ID corresponds to exactly one unique sentence.\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ Note: Unique IDs and unique text counts differ.\")\n",
    "        print(\"This usually happens if the exact same sentence appears twice in different files.\")\n",
    "else:\n",
    "    print(\"Error: 2014_rest_reviews.csv not found in Processed_Data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a880839b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015 Processor fixed for your specific JSON structure.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "def process_semeval_2015(folder_name, output_filename):\n",
    "    unified_rows = []\n",
    "    global_idx = 1\n",
    "    target_path = os.path.join(RAW_DIR, folder_name)\n",
    "    files = [f for f in os.listdir(target_path) if f.endswith('.jsonl')]\n",
    "    \n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(target_path, file_name)\n",
    "        print(f\"Reading: {file_name}\")\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line_num, line in enumerate(f, 1):\n",
    "                if not line.strip(): continue\n",
    "                item = json.loads(line)\n",
    "                \n",
    "                # Based on your structure: \"input\": [\"Sentence Text\"]\n",
    "                if 'input' in item and isinstance(item['input'], list) and len(item['input']) > 0:\n",
    "                    text = item['input'][0].strip()\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                # Get the output string\n",
    "                output_str = item.get('output', '[]')\n",
    "                try:\n",
    "                    # Converts \"[['Al Di La', 'rest general', 'positive']]\" to list\n",
    "                    opinions = ast.literal_eval(output_str)\n",
    "                except:\n",
    "                    opinions = []\n",
    "\n",
    "                for op in opinions:\n",
    "                    # Your format is [Aspect, Category, Polarity]\n",
    "                    # We only need Aspect (op[0]) and Polarity (op[2])\n",
    "                    aspect_term = op[0]\n",
    "                    polarity = op[2] \n",
    "                    \n",
    "                    if str(aspect_term).upper() == \"NULL\" or not aspect_term:\n",
    "                        final_aspect, start_idx, end_idx = \"[ASPECT]\", 0, 0\n",
    "                    else:\n",
    "                        final_aspect = aspect_term\n",
    "                        start_idx = text.find(aspect_term)\n",
    "                        if start_idx == -1:\n",
    "                            start_idx, end_idx = 0, 0\n",
    "                        else:\n",
    "                            end_idx = start_idx + len(aspect_term)\n",
    "                    \n",
    "                    unified_rows.append({\n",
    "                        \"sentence_id\": f\"2015_{global_idx:04d}\",\n",
    "                        \"sentence\": text,\n",
    "                        \"aspect\": final_aspect,\n",
    "                        \"from\": start_idx,\n",
    "                        \"to\": end_idx,\n",
    "                        \"polarity\": polarity.lower().strip()\n",
    "                    })\n",
    "                \n",
    "                global_idx += 1\n",
    "\n",
    "    df = pd.DataFrame(unified_rows)\n",
    "    output_path = os.path.join(PROCESSED_DIR, output_filename)\n",
    "    df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "    return df\n",
    "\n",
    "print(\"2015 Processor fixed for your specific JSON structure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afbb089d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: test.jsonl\n",
      "Reading: train.jsonl\n",
      "Reading: val.jsonl\n",
      "\n",
      "2015 Processing Complete!\n",
      "Total Rows Extracted: 2838\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>aspect</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_0001</td>\n",
       "      <td>Love Al Di La</td>\n",
       "      <td>Al Di La</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_0002</td>\n",
       "      <td>I recommend this place to everyone.</td>\n",
       "      <td>place</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_0003</td>\n",
       "      <td>Great food.</td>\n",
       "      <td>food</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_0004</td>\n",
       "      <td>One of my favorite places in Brooklyn.</td>\n",
       "      <td>[ASPECT]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_0005</td>\n",
       "      <td>The pastas are incredible, the risottos (parti...</td>\n",
       "      <td>pastas</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id                                           sentence    aspect  \\\n",
       "0   2015_0001                                      Love Al Di La  Al Di La   \n",
       "1   2015_0002                I recommend this place to everyone.     place   \n",
       "2   2015_0003                                        Great food.      food   \n",
       "3   2015_0004             One of my favorite places in Brooklyn.  [ASPECT]   \n",
       "4   2015_0005  The pastas are incredible, the risottos (parti...    pastas   \n",
       "\n",
       "   from  to  polarity  \n",
       "0     5  13  positive  \n",
       "1    17  22  positive  \n",
       "2     6  10  positive  \n",
       "3     0   0  positive  \n",
       "4     4  10  positive  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the processor for the res_2015 folder\n",
    "df_2015 = process_semeval_2015(\"res_2015\", \"2015_rest_reviews.csv\")\n",
    "\n",
    "print(f\"\\n2015 Processing Complete!\")\n",
    "print(f\"Total Rows Extracted: {len(df_2015)}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Display a sample including potential [ASPECT] placeholders\n",
    "df_2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01f39307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual JSON structure: {\"task_type\": \"generation\", \"dataset\": \"semeval-2015\", \"input\": [\"Love Al Di La\"], \"output\": \"[['Al Di La', 'restaurant general', 'positive']]\", \"situation\": \"none\", \"label\": \"\", \"extra\": \"\", \"instruction\": \"Task: Extracting aspect terms, aspect categories and their corresponding sentiment polarities. Input: A sentence. Output: A list of 3-tuples where each tuple contains the extracted aspect term , aspect category their corresponding sentiment polarity. Supplement: \\\"Null\\\" means that there is no occurrence in the sentence. Example:  Input: \\\"Delicate spices, onions, eggs and a kick-ass roti.\\\"  Output: [['spices', 'food quality', 'positive'], ['onions', 'food quality', 'positive'], ['eggs', 'food quality', 'positive'], ['roti', 'food quality', 'positive']] \"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the first line of the 2015 test file\n",
    "with open(os.path.join(RAW_DIR, \"res_2015\", \"test.jsonl\"), 'r') as f:\n",
    "    first_line = f.readline()\n",
    "    print(\"Actual JSON structure:\", first_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0c3896b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2015 Data Verification ---\n",
      "Total rows (Aspect-level): 2838\n",
      "Unique sentence IDs:       1929\n",
      "Average aspects/sentence:  1.47\n",
      "Sentences with >1 aspect:  909\n",
      "Implicit aspects ([ASPECT]): 698\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: 2015 Data Verification\n",
    "if 'df_2015' in locals():\n",
    "    total_rows_2015 = len(df_2015)\n",
    "    unique_ids_2015 = df_2015['sentence_id'].nunique()\n",
    "    avg_aspects_2015 = total_rows_2015 / unique_ids_2015 if unique_ids_2015 > 0 else 0\n",
    "    \n",
    "    print(\"--- 2015 Data Verification ---\")\n",
    "    print(f\"Total rows (Aspect-level): {total_rows_2015}\")\n",
    "    print(f\"Unique sentence IDs:       {unique_ids_2015}\")\n",
    "    print(f\"Average aspects/sentence:  {avg_aspects_2015:.2f}\")\n",
    "    \n",
    "    # Check for multi-aspect sentences\n",
    "    multi_aspect_2015 = total_rows_2015 - unique_ids_2015\n",
    "    print(f\"Sentences with >1 aspect:  {multi_aspect_2015}\")\n",
    "    \n",
    "    # Check for [ASPECT] placeholders\n",
    "    null_count = len(df_2015[df_2015['aspect'] == '[ASPECT]'])\n",
    "    print(f\"Implicit aspects ([ASPECT]): {null_count}\")\n",
    "else:\n",
    "    print(\"df_2015 not found. Please run the processing cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "807d554a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 2016 Processor ready. It will capture Train, Test (.gold), and Trial files.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def process_semeval_2016_sb1(folder_name, output_filename):\n",
    "    unified_rows = []\n",
    "    global_idx = 1\n",
    "    \n",
    "    target_path = os.path.join(RAW_DIR, folder_name)\n",
    "    \n",
    "    # NEW FILTER: Captures anything with \"SB1\" in the name, \n",
    "    # covering .xml, .xml.gold, and trial files.\n",
    "    files = [f for f in os.listdir(target_path) if 'SB1' in f.upper()]\n",
    "    \n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(target_path, file_name)\n",
    "        print(f\"Reading 2016 File: {file_name}\")\n",
    "        \n",
    "        try:\n",
    "            tree = ET.parse(file_path)\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            # Use './/sentence' to find sentences even if they are deep in a <Review> tag\n",
    "            for sentence in root.findall('.//sentence'):\n",
    "                text_node = sentence.find('text')\n",
    "                if text_node is None or text_node.text is None:\n",
    "                    continue\n",
    "                    \n",
    "                text = text_node.text.strip()\n",
    "                opinions = sentence.find('Opinions')\n",
    "                \n",
    "                if opinions is not None:\n",
    "                    for op in opinions.findall('Opinion'):\n",
    "                        target = op.get('target')\n",
    "                        \n",
    "                        # Handle NULL Aspects\n",
    "                        if not target or str(target).upper() == \"NULL\":\n",
    "                            final_aspect, start, end = \"[ASPECT]\", 0, 0\n",
    "                        else:\n",
    "                            final_aspect = target\n",
    "                            start = int(op.get('from', 0))\n",
    "                            end = int(op.get('to', 0))\n",
    "                        \n",
    "                        unified_rows.append({\n",
    "                            \"sentence_id\": f\"2016_{global_idx:04d}\",\n",
    "                            \"sentence\": text,\n",
    "                            \"aspect\": final_aspect,\n",
    "                            \"from\": start,\n",
    "                            \"to\": end,\n",
    "                            \"polarity\": op.get('polarity').lower().strip()\n",
    "                        })\n",
    "                global_idx += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error skipping {file_name}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(unified_rows)\n",
    "    output_path = os.path.join(PROCESSED_DIR, output_filename)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    return df\n",
    "\n",
    "print(\"Final 2016 Processor ready. It will capture Train, Test (.gold), and Trial files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab19757d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 2016 File: ABSA16_Restaurants_Train_SB1_v2.xml\n",
      "Reading 2016 File: EN_REST_SB1_TEST.xml.gold\n",
      "\n",
      "Total rows captured for 2016: 3366\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>aspect</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016_0001</td>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>place</td>\n",
       "      <td>51</td>\n",
       "      <td>56</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016_0002</td>\n",
       "      <td>We, there were four of us, arrived at noon - t...</td>\n",
       "      <td>staff</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016_0003</td>\n",
       "      <td>They never brought us complimentary noodles, i...</td>\n",
       "      <td>[ASPECT]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016_0004</td>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>food</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016_0004</td>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>portions</td>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id                                           sentence    aspect  \\\n",
       "0   2016_0001  Judging from previous posts this used to be a ...     place   \n",
       "1   2016_0002  We, there were four of us, arrived at noon - t...     staff   \n",
       "2   2016_0003  They never brought us complimentary noodles, i...  [ASPECT]   \n",
       "3   2016_0004  The food was lousy - too sweet or too salty an...      food   \n",
       "4   2016_0004  The food was lousy - too sweet or too salty an...  portions   \n",
       "\n",
       "   from  to  polarity  \n",
       "0    51  56  negative  \n",
       "1    75  80  negative  \n",
       "2     0   0  negative  \n",
       "3     4   8  negative  \n",
       "4    52  60  negative  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute the call for 2016\n",
    "df_2016 = process_semeval_2016_sb1(\"res_2016\", \"2016_rest_reviews.csv\")\n",
    "\n",
    "# Quick Verification\n",
    "print(f\"\\nTotal rows captured for 2016: {len(df_2016)}\")\n",
    "df_2016.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674f9428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2016 Data Verification ---\n",
      "Total Aspect-Level Rows: 3366\n",
      "Unique Sentence IDs:      2295\n",
      "Average Aspects/Sentence: 1.47\n",
      "Sentences with >1 aspect: 1071\n",
      "Explicit Aspects:         2530\n",
      "Implicit ([ASPECT]):      836\n",
      "\n",
      "--- Sentiment Distribution (2016) ---\n",
      "polarity\n",
      "positive    2268\n",
      "negative     953\n",
      "neutral      145\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if the 2016 dataframe exists in memory\n",
    "if 'df_2016' in locals():\n",
    "    total_rows_2016 = len(df_2016)\n",
    "    unique_ids_2016 = df_2016['sentence_id'].nunique()\n",
    "    avg_aspects_2016 = total_rows_2016 / unique_ids_2016 if unique_ids_2016 > 0 else 0\n",
    "    \n",
    "    print(\"--- 2016 Data Verification ---\")\n",
    "    print(f\"Total Aspect-Level Rows: {total_rows_2016}\")\n",
    "    print(f\"Unique Sentence IDs:      {unique_ids_2016}\")\n",
    "    print(f\"Average Aspects/Sentence: {avg_aspects_2016:.2f}\")\n",
    "    \n",
    "    # Check for multi-aspect density\n",
    "    multi_aspect_2016 = total_rows_2016 - unique_ids_2016\n",
    "    print(f\"Sentences with >1 aspect: {multi_aspect_2016}\")\n",
    "    \n",
    "    # Implicit vs Explicit check\n",
    "    implicit_count = len(df_2016[df_2016['aspect'] == '[ASPECT]'])\n",
    "    explicit_count = total_rows_2016 - implicit_count\n",
    "    print(f\"Explicit Aspects:         {explicit_count}\")\n",
    "    print(f\"Implicit ([ASPECT]):      {implicit_count}\")\n",
    "    \n",
    "   \n",
    "else:\n",
    "    print(\"Error: df_2016 not found. Please run the 2016 processing cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3e48c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bash_ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
