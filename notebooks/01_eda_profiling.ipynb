{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "## Joint Aspect Extraction & Sentiment Classification\n",
    "### SemEval Restaurant Reviews Dataset (2014, 2015, 2016)\n",
    "#\n",
    "---\n",
    "#\n",
    "## \ud83d\udcca Project Overview\n",
    "#\n",
    "This notebook performs comprehensive Exploratory Data Analysis on three SemEval restaurant review datasets for the task of:\n",
    "- **Aspect Term Extraction**: Identifying specific aspects mentioned in reviews (e.g., \"food\", \"service\", \"ambiance\")\n",
    "- **Aspect Sentiment Classification**: Determining the sentiment polarity towards each aspect (positive, negative, neutral, conflict)\n",
    "#\n",
    "### \ud83c\udfaf Objectives\n",
    "1. Understand the structure and characteristics of each dataset independently\n",
    "2. Analyze sentiment distribution and class imbalance\n",
    "3. Identify data quality issues and preprocessing needs\n",
    "4. Enable comparison with SOTA (State-of-the-Art) models on individual datasets\n",
    "5. Extract actionable insights for model development\n",
    "#\n",
    "### \ud83d\udcda Datasets\n",
    "- **SemEval-2014 Task 4**: Restaurant reviews with aspect-level annotations\n",
    "- **SemEval-2015 Task 12**: Restaurant reviews with aspect-level annotations  \n",
    "- **SemEval-2016 Task 5**: Restaurant reviews with aspect-level annotations\n",
    "#\n",
    "Each dataset will be analyzed **separately** to maintain dataset integrity for independent model training and evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#\n",
    "## 1\ufe0f\u20e3 Environment Setup\n",
    "#\n",
    "Setting up libraries, configurations, and helper functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Standard Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "    WORDCLOUD_AVAILABLE = True\n",
    "except ImportError:\n",
    "    WORDCLOUD_AVAILABLE = False\n",
    "    print(\"\u26a0\ufe0f WordCloud not available. Install with: pip install wordcloud\")\n",
    "\n",
    "# NLP\n",
    "import re\n",
    "from collections import Counter\n",
    "try:\n",
    "    import nltk\n",
    "    from nltk.util import ngrams\n",
    "    NLTK_AVAILABLE = True\n",
    "except ImportError:\n",
    "    NLTK_AVAILABLE = False\n",
    "    print(\"\u26a0\ufe0f NLTK not available. Install with: pip install nltk\")\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Plotting Style\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "print(\"\u2705 Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Helper Functions for Reusability\n",
    "\n",
    "def print_section_header(title):\n",
    "    \"\"\"Print formatted section header\"\"\"\n",
    "    print(\"\\\\n\" + \"=\"*80)\n",
    "    print(f\"  {title}\")\n",
    "    print(\"=\"*80 + \"\\\\n\")\n",
    "\n",
    "def calculate_class_weights(df, column='polarity'):\n",
    "    \"\"\"Calculate class distribution and imbalance metrics\"\"\"\n",
    "    dist = df[column].value_counts()\n",
    "    percentages = (dist / len(df) * 100).round(2)\n",
    "    \n",
    "    result_df = pd.DataFrame({\n",
    "        'Count': dist,\n",
    "        'Percentage': percentages\n",
    "    })\n",
    "    \n",
    "    # Calculate imbalance ratio\n",
    "    max_count = dist.max()\n",
    "    min_count = dist.min()\n",
    "    imbalance_ratio =max_count / min_count if min_count > 0 else np.inf\n",
    "    \n",
    "    return result_df, imbalance_ratio\n",
    "\n",
    "def plot_sentiment_distribution(df, dataset_name, ax=None):\n",
    "    \"\"\"Plot sentiment distribution with percentages\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    sentiment_counts = df['polarity'].value_counts()\n",
    "    colors_map = {\n",
    "        'positive': '#2ecc71',\n",
    "        'negative': '#e74c3c',\n",
    "        'neutral': '#95a5a6',\n",
    "        'conflict': '#f39c12'\n",
    "    }\n",
    "    colors = [colors_map.get(sent, '#3498db') for sent in sentiment_counts.index]\n",
    "    \n",
    "    bars = ax.bar(sentiment_counts.index, sentiment_counts.values, color=colors, edgecolor='black', alpha=0.7)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}\\\\n({height/len(df)*100:.1f}%)',\n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    ax.set_title(f'Sentiment Distribution - {dataset_name}', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Sentiment Polarity', fontsize=12)\n",
    "    ax.set_ylabel('Count', fontsize=12)\n",
    "    ax.set_ylim(0, sentiment_counts.max() * 1.15)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "print(\"\u2705 Helper functions defined successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#\n",
    "## 2\ufe0f\u20e3 Data Loading\n",
    "#\n",
    "Loading the three processed datasets from CSV files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define data paths\n",
    "DATA_DIR = Path(\"../Data/Processed_Data\")\n",
    "\n",
    "# File paths\n",
    "file_2014 = DATA_DIR / \"2014_rest_reviews.csv\"\n",
    "file_2015 = DATA_DIR / \"2015_rest_reviews.csv\"\n",
    "file_2016 = DATA_DIR / \"2016_rest_reviews.csv\"\n",
    "\n",
    "# Verify files exist\n",
    "for file_path in [file_2014, file_2015, file_2016]:\n",
    "    if not file_path.exists():\n",
    "        print(f\"\u274c File not found: {file_path}\")\n",
    "    else:\n",
    "        print(f\"\u2705 Found: {file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load datasets\n",
    "df_2014 = pd.read_csv(file_2014)\n",
    "df_2015 = pd.read_csv(file_2015)\n",
    "df_2016 = pd.read_csv(file_2016)\n",
    "\n",
    "print_section_header(\"DATA LOADED SUCCESSFULLY\")\n",
    "print(f\"\ud83d\udcc4 Dataset 2014: {df_2014.shape[0]:,} rows \u00d7 {df_2014.shape[1]} columns\")\n",
    "print(f\"\ud83d\udcc4 Dataset 2015: {df_2015.shape[0]:,} rows \u00d7 {df_2015.shape[1]} columns\")\n",
    "print(f\"\ud83d\udcc4 Dataset 2016: {df_2016.shape[0]:,} rows \u00d7 {df_2016.shape[1]} columns\")\n",
    "print(f\"\\\\n\ud83d\udcca Total Records: {df_2014.shape[0] + df_2015.shape[0] + df_2016.shape[0]:,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Quick preview of each dataset\n",
    "print_section_header(\"DATASET PREVIEWS\")\n",
    "\n",
    "print(\"\\\\n\ud83d\udd39 2014 Dataset Sample:\")\n",
    "display(df_2014.head(3))\n",
    "\n",
    "print(\"\\\\n\ud83d\udd39 2015 Dataset Sample:\")\n",
    "display(df_2015.head(3))\n",
    "\n",
    "print(\"\\\\n\ud83d\udd39 2016 Dataset Sample:\")\n",
    "display(df_2016.head(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#\n",
    "## 3\ufe0f\u20e3 Dataset Profiling\n",
    "#\n",
    "Comprehensive profiling of each dataset including dimensions, data types, missing values, and duplicates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "def profile_dataset(df, dataset_name):\n",
    "    \"\"\"Generate comprehensive dataset profile\"\"\"\n",
    "    print_section_header(f\"PROFILING: {dataset_name}\")\n",
    "    \n",
    "    print(f\"\ud83d\udccf Dimensions: {df.shape[0]:,} rows \u00d7 {df.shape[1]} columns\")\n",
    "    print(f\"\ud83d\udcbe Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    print(f\"\\\\n\ud83d\udccb Column Names: {list(df.columns)}\")\n",
    "    \n",
    "    print(\"\\\\n\ud83d\udd24 Data Types:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    print(\"\\\\n\u2753 Missing Values:\")\n",
    "    missing = df.isnull().sum()\n",
    "    if missing.sum() == 0:\n",
    "        print(\"  \u2705 No missing values detected!\")\n",
    "    else:\n",
    "        missing_df = pd.DataFrame({\n",
    "            'Count': missing[missing > 0],\n",
    "            'Percentage': (missing[missing > 0] / len(df) * 100).round(2)\n",
    "        })\n",
    "        print(missing_df)\n",
    "    \n",
    "    print(\"\\\\n\ud83d\udd01 Duplicate Rows:\")\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"  Total: {duplicates} ({duplicates/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    print(\"\\\\n\ud83d\udcca Summary Statistics:\")\n",
    "    display(df.describe(include='all').T)\n",
    "    \n",
    "    print(\"\\\\n\" + \"-\"*80)\n",
    "\n",
    "# Profile each dataset\n",
    "profile_dataset(df_2014, \"SemEval 2014\")\n",
    "profile_dataset(df_2015, \"SemEval 2015\")\n",
    "profile_dataset(df_2016, \"SemEval 2016\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Detailed aspect-level statistics\n",
    "def analyze_aspect_stats(df, dataset_name):\n",
    "    \"\"\"Analyze aspect-specific statistics\"\"\"\n",
    "    print_section_header(f\"ASPECT-LEVEL STATISTICS: {dataset_name}\")\n",
    "    \n",
    "    # Unique sentences vs aspect mentions\n",
    "    unique_sentences = df['sentence_id'].nunique()\n",
    "    total_aspects = len(df)\n",
    "    \n",
    "    print(f\"\ud83d\udcdd Unique Sentences: {unique_sentences:,}\")\n",
    "    print(f\"\ud83c\udff7\ufe0f  Total Aspect Mentions: {total_aspects:,}\")\n",
    "    print(f\"\ud83d\udcc8 Avg Aspects per Sentence: {total_aspects/unique_sentences:.2f}\")\n",
    "    \n",
    "    # Multi-aspect sentences\n",
    "    aspect_counts = df.groupby('sentence_id').size()\n",
    "    multi_aspect = (aspect_counts > 1).sum()\n",
    "    print(f\"\ud83d\udd22 Sentences with Multiple Aspects: {multi_aspect:,} ({multi_aspect/unique_sentences*100:.1f}%)\")\n",
    "    \n",
    "    # Unique aspects\n",
    "    unique_aspects = df[df['aspect'] != '[ASPECT]']['aspect'].nunique()\n",
    "    implicit_aspects = (df['aspect'] == '[ASPECT]').sum()\n",
    "    \n",
    "    print(f\"\\\\n\ud83c\udf1f Unique Explicit Aspects: {unique_aspects:,}\")\n",
    "    print(f\"\u2753 Implicit Aspects ([ASPECT]): {implicit_aspects:,} ({implicit_aspects/total_aspects*100:.1f}%)\")\n",
    "    \n",
    "    # Aspect term length\n",
    "    explicit_aspects = df[df['aspect'] != '[ASPECT]']\n",
    "    if len(explicit_aspects) > 0:\n",
    "        aspect_lengths = explicit_aspects['aspect'].str.len()\n",
    "        print(f\"\\\\n\ud83d\udccf Aspect Term Length (characters):\")\n",
    "        print(f\"  Min: {aspect_lengths.min()}, Max: {aspect_lengths.max()}, Mean: {aspect_lengths.mean():.1f}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"-\"*80)\n",
    "\n",
    "analyze_aspect_stats(df_2014, \"SemEval 2014\")\n",
    "analyze_aspect_stats(df_2015, \"SemEval 2015\")\n",
    "analyze_aspect_stats(df_2016, \"SemEval 2016\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#\n",
    "## 4\ufe0f\u20e3 Univariate Analysis\n",
    "#\n",
    "Analyzing individual variables - sentiment distribution, aspect frequency, and text length characteristics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Sentiment/Polarity Distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Sentiment distribution for all datasets\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "datasets = [\n",
    "    (df_2014, '2014', axes[0]),\n",
    "    (df_2015, '2015', axes[1]),\n",
    "    (df_2016, '2016', axes[2])\n",
    "]\n",
    "\n",
    "for df, year, ax in datasets:\n",
    "    plot_sentiment_distribution(df, f\"SemEval {year}\", ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics\n",
    "print_section_header(\"SENTIMENT DISTRIBUTION STATISTICS\")\n",
    "\n",
    "for df, year in [(df_2014, '2014'), (df_2015, '2015'), (df_2016, '2016')]:\n",
    "    print(f\"\\\\n\ud83d\udcca {year} Dataset:\")\n",
    "    dist, imbalance = calculate_class_weights(df)\n",
    "    print(dist)\n",
    "    print(f\"\\\\n\u2696\ufe0f  Imbalance Ratio (Max/Min): {imbalance:.2f}\")\n",
    "    print(\"-\" * 60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Top Aspects Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Top 20 aspects for each dataset\n",
    "def plot_top_aspects(df, dataset_name, top_n=20):\n",
    "    \"\"\"Plot top N aspects\"\"\"\n",
    "    # Filter out implicit aspects\n",
    "    explicit_df = df[df['aspect'] != '[ASPECT]']\n",
    "    \n",
    "    if len(explicit_df) == 0:\n",
    "        print(f\"No explicit aspects in {dataset_name}\")\n",
    "        return\n",
    "    \n",
    "    top_aspects = explicit_df['aspect'].value_counts().head(top_n)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    colors = sns.color_palette(\"viridis\", top_n)\n",
    "    bars = ax.barh(range(len(top_aspects)), top_aspects.values, color=colors, edgecolor='black', alpha=0.8)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, count) in enumerate(zip(bars, top_aspects.values)):\n",
    "        ax.text(count + max(top_aspects.values)*0.01, bar.get_y() + bar.get_height()/2, \n",
    "                f'{count}', va='center', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    ax.set_yticks(range(len(top_aspects)))\n",
    "    ax.set_yticklabels(top_aspects.index)\n",
    "    ax.set_xlabel('Frequency', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'Top {top_n} Most Frequent Aspects - {dataset_name}', \n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot for each dataset\n",
    "plot_top_aspects(df_2014, \"SemEval 2014\", 20)\n",
    "plot_top_aspects(df_2015, \"SemEval 2015\", 20)\n",
    "plot_top_aspects(df_2016, \"SemEval 2016\", 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Sentence Length Distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Calculate sentence statistics\n",
    "def analyze_sentence_lengths(df, dataset_name):\n",
    "    \"\"\"Analyze sentence length distributions\"\"\"\n",
    "    # Get unique sentences\n",
    "    unique_sentences = df.drop_duplicates(subset='sentence_id')\n",
    "    \n",
    "    # Calculate lengths\n",
    "    unique_sentences['sentence_length'] = unique_sentences['sentence'].str.len()\n",
    "    unique_sentences['word_count'] = unique_sentences['sentence'].str.split().str.len()\n",
    "    \n",
    "    print_section_header(f\"SENTENCE LENGTH ANALYSIS: {dataset_name}\")\n",
    "    \n",
    "    print(\"\ud83d\udccf Character Length:\")\n",
    "    print(unique_sentences['sentence_length'].describe())\n",
    "    \n",
    "    print(\"\\\\n\ud83d\udcdd Word Count:\")\n",
    "    print(unique_sentences['word_count'].describe())\n",
    "    \n",
    "    return unique_sentences\n",
    "\n",
    "# Analyze each dataset\n",
    "sent_2014 = analyze_sentence_lengths(df_2014, \"SemEval 2014\")\n",
    "sent_2015 = analyze_sentence_lengths(df_2015, \"SemEval 2015\")\n",
    "sent_2016 = analyze_sentence_lengths(df_2016, \"SemEval 2016\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualize sentence length distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "datasets_sent = [\n",
    "    (sent_2014, '2014', 0),\n",
    "    (sent_2015, '2015', 1),\n",
    "    (sent_2016, '2016', 2)\n",
    "]\n",
    "\n",
    "for sent_df, year, col in datasets_sent:\n",
    "    # Character length histogram\n",
    "    axes[0, col].hist(sent_df['sentence_length'], bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    axes[0, col].set_title(f'{year} - Character Length', fontweight='bold')\n",
    "    axes[0, col].set_xlabel('Characters')\n",
    "    axes[0, col].set_ylabel('Frequency')\n",
    "    axes[0, col].axvline(sent_df['sentence_length'].mean(), color='red', linestyle='--', \n",
    "                         label=f'Mean: {sent_df[\"sentence_length\"].mean():.1f}')\n",
    "    axes[0, col].legend()\n",
    "    \n",
    "    # Word count histogram\n",
    "    axes[1, col].hist(sent_df['word_count'], bins=30, color='lightcoral', edgecolor='black', alpha=0.7)\n",
    "    axes[1, col].set_title(f'{year} - Word Count', fontweight='bold')\n",
    "    axes[1, col].set_xlabel('Words')\n",
    "    axes[1, col].set_ylabel('Frequency')\n",
    "    axes[1, col].axvline(sent_df['word_count'].mean(), color='red', linestyle='--',\n",
    "                         label=f'Mean: {sent_df[\"word_count\"].mean():.1f}')\n",
    "    axes[1, col].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#\n",
    "## 5\ufe0f\u20e3 Bivariate Analysis\n",
    "#\n",
    "Exploring relationships between variables - sentiment by aspect, sentence length by sentiment, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Sentiment Breakdown for Top Aspects\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Sentiment distribution for top aspects\n",
    "def plot_aspect_sentiment(df, dataset_name, top_n=10):\n",
    "    \"\"\"Plot sentiment breakdown for top N aspects\"\"\"\n",
    "    # Get top aspects\n",
    "    explicit_df = df[df['aspect'] != '[ASPECT]']\n",
    "    top_aspects = explicit_df['aspect'].value_counts().head(top_n).index\n",
    "    \n",
    "    # Filter data\n",
    "    filtered = explicit_df[explicit_df['aspect'].isin(top_aspects)]\n",
    "    \n",
    "    # Create crosstab\n",
    "    ct = pd.crosstab(filtered['aspect'], filtered['polarity'], normalize='index') * 100\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ct.plot(kind='barh', stacked=True, ax=ax, \n",
    "            color=['#2ecc71', '#e74c3c', '#95a5a6', '#f39c12'])\n",
    "    \n",
    "    ax.set_xlabel('Percentage (%)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Aspect', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'Sentiment Distribution by Top {top_n} Aspects - {dataset_name}', \n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.legend(title='Sentiment', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print raw counts\n",
    "    print(f\"\\\\n\ud83d\udcca Counts for {dataset_name}:\")\n",
    "    print(pd.crosstab(filtered['aspect'], filtered['polarity']))\n",
    "\n",
    "plot_aspect_sentiment(df_2014, \"SemEval 2014\", 10)\n",
    "plot_aspect_sentiment(df_2015, \"SemEval 2015\", 10)\n",
    "plot_aspect_sentiment(df_2016, \"SemEval 2016\", 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Sentence Length vs Sentiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Sentence length by sentiment\n",
    "def plot_length_by_sentiment(sent_df, df, dataset_name):\n",
    "    \"\"\"Box plot of sentence length by sentiment\"\"\"\n",
    "    # Merge to get polarity for each unique sentence\n",
    "    # Take the first occurrence of each sentence_id\n",
    "    polarity_map = df.drop_duplicates('sentence_id')[['sentence_id', 'polarity']].copy()\n",
    "    \n",
    "    # Ensure sent_df has the columns we need\n",
    "    sent_df_copy = sent_df[['sentence_id', 'sentence_length', 'word_count']].copy()\n",
    "    \n",
    "    # Merge\n",
    "    sent_with_pol = sent_df_copy.merge(polarity_map, on='sentence_id', how='inner')\n",
    "    \n",
    "    # Debug: check if polarity column exists\n",
    "    if 'polarity' not in sent_with_pol.columns:\n",
    "        print(f\"ERROR: polarity column missing. Available columns: {sent_with_pol.columns.tolist()}\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Character length - use seaborn for more robust plotting\n",
    "    import seaborn as sns\n",
    "    sns.boxplot(data=sent_with_pol, x='polarity', y='sentence_length', ax=axes[0])\n",
    "    axes[0].set_title(f'{dataset_name} - Char Length by Sentiment', fontweight='bold')\n",
    "    axes[0].set_xlabel('Sentiment')\n",
    "    axes[0].set_ylabel('Character Length')\n",
    "    \n",
    "    # Word count\n",
    "    sns.boxplot(data=sent_with_pol, x='polarity', y='word_count', ax=axes[1])\n",
    "    axes[1].set_title(f'{dataset_name} - Word Count by Sentiment', fontweight='bold')\n",
    "    axes[1].set_xlabel('Sentiment')\n",
    "    axes[1].set_ylabel('Word Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_length_by_sentiment(sent_2014, df_2014, \"SemEval 2014\")\n",
    "plot_length_by_sentiment(sent_2015, df_2015, \"SemEval 2015\")\n",
    "plot_length_by_sentiment(sent_2016, df_2016, \"SemEval 2016\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Aspect Count per Sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Distribution of aspect counts per sentence\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, (df, year) in enumerate([(df_2014, '2014'), (df_2015, '2015'), (df_2016, '2016')]):\n",
    "    aspect_counts = df.groupby('sentence_id').size()\n",
    "    \n",
    "    axes[idx].hist(aspect_counts, bins=range(1, aspect_counts.max()+2), \n",
    "                   color='teal', edgecolor='black', alpha=0.7, align='left')\n",
    "    axes[idx].set_title(f'{year} - Aspects per Sentence', fontweight='bold', fontsize=12)\n",
    "    axes[idx].set_xlabel('Number of Aspects')\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].set_xticks(range(1, min(11, aspect_counts.max()+1)))\n",
    "    \n",
    "    print(f\"\\\\n\ud83d\udcca {year} - Aspect Count Distribution:\")\n",
    "    print(aspect_counts.describe())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#\n",
    "## 6\ufe0f\u20e3 T ext & NLP Analysis\n",
    "#\n",
    "Advanced text analysis including word clouds, n-grams, and vocabulary statistics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Word Clouds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Generate word clouds for sentiments\n",
    "if WORDCLOUD_AVAILABLE:\n",
    "    def generate_wordclouds(df, dataset_name):\n",
    "        \"\"\"Generate word clouds for different sentiments\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        sentiments = ['positive', 'negative', 'neutral', 'all']\n",
    "        colors = ['Greens', 'Reds', 'Greys', 'viridis']\n",
    "        \n",
    "        for idx, (sentiment, cmap) in enumerate(zip(sentiments, colors)):\n",
    "            if sentiment == 'all':\n",
    "                text = ' '.join(df['sentence'].unique())\n",
    "                title = 'All Sentiments'\n",
    "            else:\n",
    "                subset = df[df['polarity'] == sentiment]\n",
    "                if len(subset) == 0:\n",
    "                    axes[idx].text(0.5, 0.5, f'No {sentiment} samples', \n",
    "                                  ha='center', va='center', fontsize=14)\n",
    "                    axes[idx].axis('off')\n",
    "                    continue\n",
    "                text = ' '.join(subset['sentence'].unique())\n",
    "                title = f'{sentiment.capitalize()} Sentiment'\n",
    "            \n",
    "            # Generate word cloud\n",
    "            wordcloud = WordCloud(width=800, height=400, background_color='white',\n",
    "                                 colormap=cmap, max_words=100, relative_scaling=0.5).generate(text)\n",
    "            \n",
    "            axes[idx].imshow(wordcloud, interpolation='bilinear')\n",
    "            axes[idx].set_title(f'{title} - {dataset_name}', fontsize=14, fontweight='bold')\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    generate_wordclouds(df_2014, \"SemEval 2014\")\n",
    "    generate_wordclouds(df_2015, \"SemEval 2015\")\n",
    "    generate_wordclouds(df_2016, \"SemEval 2016\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f WordCloud library not available. Skipping word cloud generation.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 N-gram Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# N-gram analysis\n",
    "if NLTK_AVAILABLE:\n",
    "    def analyze_ngrams(df, dataset_name, n=2, top_k=15):\n",
    "        \"\"\"Analyze and visualize top n-grams\"\"\"\n",
    "        # Get unique sentences\n",
    "        sentences = df['sentence'].unique()\n",
    "        \n",
    "        # Tokenize and create n-grams\n",
    "        all_ngrams = []\n",
    "        for sent in sentences:\n",
    "            # Simple tokenization (lowercase, remove punctuation)\n",
    "            tokens = re.findall(r'\\\\b\\\\w+\\\\b', sent.lower())\n",
    "            all_ngrams.extend(list(ngrams(tokens, n)))\n",
    "        \n",
    "        # Count and get top k\n",
    "        ngram_counts = Counter(all_ngrams)\n",
    "        top_ngrams = ngram_counts.most_common(top_k)\n",
    "        \n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        \n",
    "        ngram_labels = [' '.join(ng) for ng, _ in top_ngrams]\n",
    "        ngram_values = [count for _, count in top_ngrams]\n",
    "        \n",
    "        colors = sns.color_palette(\"rocket\", top_k)\n",
    "        bars = ax.barh(range(len(ngram_labels)), ngram_values, color=colors, edgecolor='black', alpha=0.8)\n",
    "        \n",
    "        # Add value labels\n",
    "        for i, (bar, count) in enumerate(zip(bars, ngram_values)):\n",
    "            ax.text(count + max(ngram_values)*0.01, bar.get_y() + bar.get_height()/2,\n",
    "                    f'{count}', va='center', fontweight='bold', fontsize=9)\n",
    "        \n",
    "        ax.set_yticks(range(len(ngram_labels)))\n",
    "        ax.set_yticklabels(ngram_labels)\n",
    "        ax.set_xlabel('Frequency', fontsize=12, fontweight='bold')\n",
    "        ax.set_title(f'Top {top_k} {n}-grams - {dataset_name}', fontsize=14, fontweight='bold', pad=20)\n",
    "        ax.invert_yaxis()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Bigrams\n",
    "    print_section_header(\"BIGRAM ANALYSIS\")\n",
    "    analyze_ngrams(df_2014, \"SemEval 2014\", n=2, top_k=15)\n",
    "    analyze_ngrams(df_2015, \"SemEval 2015\", n=2, top_k=15)\n",
    "    analyze_ngrams(df_2016, \"SemEval 2016\", n=2, top_k=15)\n",
    "    \n",
    "    # Trigrams\n",
    "    print_section_header(\"TRIGRAM ANALYSIS\")\n",
    "    analyze_ngrams(df_2014, \"SemEval 2014\", n=3, top_k=15)\n",
    "    analyze_ngrams(df_2015, \"SemEval 2015\", n=3, top_k=15)\n",
    "    analyze_ngrams(df_2016, \"SemEval 2016\", n=3, top_k=15)\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f NLTK library not available. Skipping n-gram analysis.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Vocabulary Richness\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Vocabulary statistics\n",
    "def vocabulary_stats(df, dataset_name):\n",
    "    \"\"\"Calculate vocabulary richness metrics\"\"\"\n",
    "    print_section_header(f\"VOCABULARY STATISTICS: {dataset_name}\")\n",
    "    \n",
    "    unique_sentences = df['sentence'].unique()\n",
    "    all_text = ' '.join(unique_sentences)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = re.findall(r'\\\\b\\\\w+\\\\b', all_text.lower())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    total_tokens = len(tokens)\n",
    "    unique_tokens = len(set(tokens))\n",
    "    type_token_ratio = unique_tokens / total_tokens if total_tokens > 0 else 0\n",
    "    \n",
    "    print(f\"\ud83d\udcdd Total Tokens: {total_tokens:,}\")\n",
    "    print(f\"\ud83c\udf1f Unique Tokens (Vocabulary Size): {unique_tokens:,}\")\n",
    "    print(f\"\ud83d\udcca Type-Token Ratio (TTR): {type_token_ratio:.4f}\")\n",
    "    print(f\"\ud83d\udccf Average Token Length: {np.mean([len(t) for t in tokens]):.2f} characters\")\n",
    "    \n",
    "    # Most common words\n",
    "    word_counts = Counter(tokens)\n",
    "    print(f\"\\\\n\ud83d\udd1d Top 20 Most Frequent Words:\")\n",
    "    for word, count in word_counts.most_common(20):\n",
    "        print(f\"  {word}: {count}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"-\"*80)\n",
    "\n",
    "vocabulary_stats(df_2014, \"SemEval 2014\")\n",
    "vocabulary_stats(df_2015, \"SemEval 2015\")\n",
    "vocabulary_stats(df_2016, \"SemEval 2016\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#\n",
    "## 7\ufe0f\u20e3 Cross-Dataset Comparison\n",
    "#\n",
    "Comparing characteristics across all three datasets to identify similarities and differences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create comparison summary table\n",
    "print_section_header(\"CROSS-DATASET COMPARISON SUMMARY\")\n",
    "\n",
    "comparison_data = []\n",
    "\n",
    "for df, year in [(df_2014, '2014'), (df_2015, '2015'), (df_2016, '2016')]:\n",
    "    unique_sentences = df['sentence_id'].nunique()\n",
    "    total_aspects = len(df)\n",
    "    unique_aspects = df[df['aspect'] != '[ASPECT]']['aspect'].nunique()\n",
    "    implicit = (df['aspect'] == '[ASPECT]').sum()\n",
    "    \n",
    "    # Sentiment distribution\n",
    "    sent_dist = df['polarity'].value_counts()\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Dataset': f'SemEval {year}',\n",
    "        'Unique Sentences': unique_sentences,\n",
    "        'Total Aspects': total_aspects,\n",
    "        'Avg Aspects/Sentence': round(total_aspects/unique_sentences, 2),\n",
    "        'Unique Explicit Aspects': unique_aspects,\n",
    "        'Implicit Aspects': implicit,\n",
    "        'Positive': sent_dist.get('positive', 0),\n",
    "        'Negative': sent_dist.get('negative', 0),\n",
    "        'Neutral': sent_dist.get('neutral', 0),\n",
    "        'Conflict': sent_dist.get('conflict', 0)\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "display(comparison_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualize dataset size comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "datasets = ['2014', '2015', '2016']\n",
    "sentences = [comparison_df.iloc[i]['Unique Sentences'] for i in range(3)]\n",
    "aspects = [comparison_df.iloc[i]['Total Aspects'] for i in range(3)]\n",
    "\n",
    "x = np.arange(len(datasets))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, sentences, width, label='Unique Sentences', color='steelblue', alpha=0.8)\n",
    "axes[0].bar(x + width/2, aspects, width, label='Total Aspects', color='coral', alpha=0.8)\n",
    "axes[0].set_xlabel('Dataset', fontweight='bold')\n",
    "axes[0].set_ylabel('Count', fontweight='bold')\n",
    "axes[0].set_title('Dataset Size Comparison', fontweight='bold', fontsize=14)\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(datasets)\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (s, a) in enumerate(zip(sentences, aspects)):\n",
    "    axes[0].text(i - width/2, s + 50, str(s), ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    axes[0].text(i + width/2, a + 50, str(a), ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "\n",
    "# Sentiment comparison\n",
    "sentiment_comp = comparison_df[['Dataset', 'Positive', 'Negative', 'Neutral', 'Conflict']].set_index('Dataset')\n",
    "sentiment_comp.plot(kind='bar', ax=axes[1], color=['#2ecc71', '#e74c3c', '#95a5a6', '#f39c12'], alpha=0.8)\n",
    "axes[1].set_xlabel('Dataset', fontweight='bold')\n",
    "axes[1].set_ylabel('Count', fontweight='bold')\n",
    "axes[1].set_title('Sentiment Distribution Comparison', fontweight='bold', fontsize=14)\n",
    "axes[1].legend(title='Sentiment')\n",
    "axes[1].set_xticklabels(datasets, rotation=0)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Aspect overlap analysis\n",
    "print_section_header(\"ASPECT OVERLAP ANALYSIS\")\n",
    "\n",
    "# Get explicit aspects from each dataset\n",
    "aspects_2014 = set(df_2014[df_2014['aspect'] != '[ASPECT]']['aspect'].unique())\n",
    "aspects_2015 = set(df_2015[df_2015['aspect'] != '[ASPECT]']['aspect'].unique())\n",
    "aspects_2016 = set(df_2016[df_2016['aspect'] != '[ASPECT]']['aspect'].unique())\n",
    "\n",
    "print(f\"\ud83d\udd39 2014 Unique Aspects: {len(aspects_2014)}\")\n",
    "print(f\"\ud83d\udd39 2015 Unique Aspects: {len(aspects_2015)}\")\n",
    "print(f\"\ud83d\udd39 2016 Unique Aspects: {len(aspects_2016)}\")\n",
    "\n",
    "# Overlaps\n",
    "overlap_14_15 = aspects_2014.intersection(aspects_2015)\n",
    "overlap_14_16 = aspects_2014.intersection(aspects_2016)\n",
    "overlap_15_16 = aspects_2015.intersection(aspects_2016)\n",
    "overlap_all = aspects_2014.intersection(aspects_2015).intersection(aspects_2016)\n",
    "\n",
    "print(f\"\\\\n\ud83d\udd17 Overlap 2014 \u2229 2015: {len(overlap_14_15)} aspects\")\n",
    "print(f\"\ud83d\udd17 Overlap 2014 \u2229 2016: {len(overlap_14_16)} aspects\")\n",
    "print(f\"\ud83d\udd17 Overlap 2015 \u2229 2016: {len(overlap_15_16)} aspects\")\n",
    "print(f\"\ud83d\udd17 Common to All Three: {len(overlap_all)} aspects\")\n",
    "\n",
    "if len(overlap_all) > 0:\n",
    "    print(f\"\\\\n\ud83d\udccb Common Aspects (in all datasets): {sorted(list(overlap_all))[:20]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Class imbalance assessment\n",
    "print_section_header(\"CLASS IMBALANCE ASSESSMENT\")\n",
    "\n",
    "for df, year in [(df_2014, '2014'), (df_2015, '2015'), (df_2016, '2016')]:\n",
    "    dist, imbalance = calculate_class_weights(df)\n",
    "    \n",
    "    print(f\"\\\\n\ud83d\udcca SemEval {year}:\")\n",
    "    print(dist)\n",
    "    print(f\"\\\\n\u2696\ufe0f  Imbalance Ratio: {imbalance:.2f}\")\n",
    "    \n",
    "    if imbalance > 5:\n",
    "        print(f\"\u26a0\ufe0f  WARNING: Significant class imbalance detected!\")\n",
    "    elif imbalance > 3:\n",
    "        print(f\"\u26a0\ufe0f  CAUTION: Moderate class imbalance detected.\")\n",
    "    else:\n",
    "        print(f\"\u2705 Relatively balanced classes.\")\n",
    "    \n",
    "    print(\"-\" * 70)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#\n",
    "## 8\ufe0f\u20e3 Key Findings & Recommendations\n",
    "#\n",
    "### \ud83d\udcca Data Quality Observations\n",
    "#\n",
    "#### Dataset Characteristics\n",
    "- **SemEval 2014**: Largest dataset with ~2,681 unique sentences and ~4,923 aspect mentions\n",
    "- **SemEval 2015**: Medium-sized with ~1,929 sentences and ~2,838 aspects  \n",
    "- **SemEval 2016**: Comparable to 2015 with ~2,295 sentences and ~3,366 aspects\n",
    "- All datasets contain **implicit aspects** (marked as `[ASPECT]`), particularly in 2015 and 2016\n",
    "#\n",
    "#### Sentiment Distribution\n",
    "- **Positive sentiment dominates** across all datasets (~60-70%)\n",
    "- **Negative sentiment** represents 15-30% of samples\n",
    "- **Neutral and Conflict** classes are underrepresented (<10% combined)\n",
    "- **Class imbalance** is present and should be addressed during model training\n",
    "#\n",
    "#### Text Characteristics\n",
    "- Average sentence length: **50-100 characters** (10-20 words)\n",
    "- Multiple aspect mentions per sentence are common (avg ~1.5-1.8 aspects/sentence)\n",
    "- Vocabulary is domain-specific (restaurant reviews) with frequent food-related terms\n",
    "#\n",
    "### \ud83d\udea8 Data Quality Issues\n",
    "#\n",
    "1. **Class Imbalance**: Positive sentiment heavily outweighs other classes\n",
    "2. **Implicit Aspects**: Presence of `[ASPECT]` placeholders requires special handling\n",
    "3. **Multi-aspect Sentences**: Models must handle sentences with multiple aspect-sentiment pairs\n",
    "4. **Vocabulary Overlap**: While there's overlap between datasets, each has unique aspects\n",
    "#\n",
    "### \ud83d\udca1 Recommendations for Modeling\n",
    "#\n",
    "#### Preprocessing\n",
    "- **Handle Implicit Aspects**: Decide strategy - filter out, special token, or contextual classification\n",
    "- **Text Normalization**: Lowercase, remove extra spaces, handle contractions\n",
    "- **Aspect Boundary Handling**: Leverage `from`/`to` indices for span-based models\n",
    "#\n",
    "#### Model Training\n",
    "- **Class Weights**: Apply class weights or focal loss to address imbalance\n",
    "- **Data Augmentation**: Consider paraphrase-based augmentation for underrepresented classes\n",
    "- **Cross-validation**: Use stratified k-fold to maintain class distribution\n",
    "- **Separate Evaluation**: Train and evaluate on each dataset independently for SOTA comparison\n",
    "#\n",
    "#### Model Architecture\n",
    "- **Contextual Embeddings**: Use transformer-based models (BERT, RoBERTa, **ModernBERT**)\n",
    "- **Graph Attention**: RGAT for modeling aspect-opinion relationships\n",
    "- **Joint Training**: Multi-task learning for aspect extraction + sentiment classification\n",
    "#\n",
    "#### Evaluation Metrics\n",
    "- **F1-Score**: Macro and Micro F1 for handling imbalance\n",
    "- **Per-Class Metrics**: Precision, Recall, F1 for each sentiment class\n",
    "- **Aspect-Level Metrics**: Strict and relaxed matching for aspect extraction\n",
    "- **Comparison with SOTA**: Report metrics on each dataset separately\n",
    "#\n",
    "### \u2705 Next Steps\n",
    "#\n",
    "1. **Data Preprocessing Pipeline**: Implement robust cleaning and tokenization\n",
    "2. **Train-Val-Test Split**: Ensure stratified splits if not pre-defined\n",
    "3. **Baseline Model**: Start with simpler models (LogReg, BiLSTM) for baseline\n",
    "4. **SOTA Model Implementation**: ModernBERT + RGAT architecture\n",
    "5. **Hyperparameter Tuning**: Grid search or Bayesian optimization\n",
    "6. **Error Analysis**: Analyze misclassifications to improve model\n",
    "#\n",
    "---\n",
    "#\n",
    "**\ud83c\udfaf This notebook provides a solid foundation for developing a professional SOTA model for joint aspect extraction and sentiment classification on restaurant reviews.**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}