{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 04 - Training Engine\n",
                "\n",
                "Training the ModernBERT-RGAT joint model on SemEval restaurant datasets:\n",
                "\n",
                "1. Setup and imports\n",
                "2. Loss function unit tests\n",
                "3. Single-batch overfit sanity check\n",
                "4. Train on SemEval 2014\n",
                "5. Train on SemEval 2015\n",
                "6. Train on SemEval 2016\n",
                "7. Training curves visualization\n",
                "8. Results summary\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import subprocess, sys, os\n",
                "\n",
                "# ---------------------------------------------------------------\n",
                "# SELECT THE MIG DEVICE WITH FREE MEMORY\n",
                "# The H100 has 3 MIG partitions. Device 0 & 1 are nearly full.\n",
                "# Device 2 has ~8 GB free -- more than enough for ModernBERT-RGAT.\n",
                "# This MUST be set before importing torch.\n",
                "# ---------------------------------------------------------------\n",
                "os.environ['CUDA_VISIBLE_DEVICES'] = 'MIG-be0d4dc8-2244-5ed0-89ec-b674eacb6a9b'\n",
                "print(f'CUDA_VISIBLE_DEVICES = {os.environ[\"CUDA_VISIBLE_DEVICES\"]}')\n",
                "\n",
                "def install_if_missing(package, pip_name=None):\n",
                "    try:\n",
                "        __import__(package)\n",
                "    except ImportError:\n",
                "        print(f'Installing {pip_name or package}...')\n",
                "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pip_name or package])\n",
                "\n",
                "install_if_missing('sklearn', 'scikit-learn')\n",
                "install_if_missing('transformers', 'transformers')\n",
                "install_if_missing('spacy', 'spacy')\n",
                "\n",
                "import spacy\n",
                "try:\n",
                "    spacy.load('en_core_web_sm')\n",
                "except OSError:\n",
                "    subprocess.check_call([sys.executable, '-m', 'spacy', 'download', 'en_core_web_sm'])\n",
                "\n",
                "print('Dependencies ready.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "PROJECT_ROOT = os.path.expanduser('~/SOTA-ModernBERT-RGAT-Joint-Aspect-Sentiment-Extraction-for-Food-Tech-Reviews')\n",
                "assert os.path.isdir(PROJECT_ROOT), f'Project root not found: {PROJECT_ROOT}'\n",
                "if PROJECT_ROOT not in sys.path:\n",
                "    sys.path.insert(0, PROJECT_ROOT)\n",
                "os.chdir(PROJECT_ROOT)\n",
                "print(f'Project root: {PROJECT_ROOT}')\n",
                "\n",
                "import torch\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from src.model import ModernBERT_RGAT\n",
                "from src.dataset import ABSAPreprocessor, ABSADataset, create_dataloader\n",
                "from src.data_pipeline import load_config, build_splits, compute_class_weights\n",
                "from src.losses import JointTaskLoss, FocalLoss, AlphaScheduler\n",
                "from src.trainer import Trainer, compute_strict_f1, extract_spans_from_bio\n",
                "\n",
                "print(f'PyTorch: {torch.__version__}')\n",
                "print(f'CUDA available: {torch.cuda.is_available()}')\n",
                "assert torch.cuda.is_available(), 'CUDA must be available!'\n",
                "\n",
                "device = torch.device('cuda')\n",
                "print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
                "print(f'Device count: {torch.cuda.device_count()}')\n",
                "\n",
                "try:\n",
                "    free_bytes, total_bytes = torch.cuda.mem_get_info(0)\n",
                "    print(f'GPU memory: {total_bytes/1024**3:.1f} GB total, {free_bytes/1024**3:.1f} GB free')\n",
                "except Exception as e:\n",
                "    print(f'mem_get_info error: {e}')\n",
                "\n",
                "print(f'Using device: {device}')\n",
                "print('Imports successful.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "config_path = os.path.join(PROJECT_ROOT, 'configs', 'config.yaml')\n",
                "config = load_config(config_path)\n",
                "\n",
                "print('Config loaded.')\n",
                "print(f'  Epochs:       {config[\"training\"][\"epochs\"]}')\n",
                "print(f'  Batch size:   {config[\"training\"][\"batch_size\"]}')\n",
                "print(f'  LR:           {config[\"training\"][\"learning_rate\"]}')\n",
                "print(f'  Alpha:        {config[\"training\"][\"alpha_start\"]} -> {config[\"training\"][\"alpha_end\"]}')\n",
                "print(f'  Focal gamma:  {config[\"training\"][\"focal_gamma\"]}')\n",
                "print(f'  FP16:         {config[\"training\"][\"fp16\"]}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Loss Function Unit Tests"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verifying the loss function works correctly before training\n",
                "# These tests run on CPU (no GPU needed for small tensors)\n",
                "\n",
                "print('Test 1: JointTaskLoss forward pass')\n",
                "dummy_ate_logits = torch.randn(2, 96, 3, requires_grad=True)\n",
                "dummy_ate_labels = torch.randint(0, 3, (2, 96))\n",
                "dummy_asc_logits = torch.randn(2, 4, requires_grad=True)\n",
                "dummy_asc_labels = torch.randint(0, 4, (2,))\n",
                "\n",
                "loss_fn = JointTaskLoss(alpha_start=0.7, alpha_end=0.3, gamma=2.0, total_steps=100)\n",
                "total, ate, asc = loss_fn(dummy_ate_logits, dummy_ate_labels, dummy_asc_logits, dummy_asc_labels)\n",
                "print(f'  Total: {total.item():.4f}, ATE: {ate.item():.4f}, ASC: {asc.item():.4f}')\n",
                "\n",
                "# Verify gradients flow\n",
                "total.backward()\n",
                "print(f'  ATE logits grad shape: {dummy_ate_logits.grad.shape}')\n",
                "print(f'  ASC logits grad shape: {dummy_asc_logits.grad.shape}')\n",
                "print('  Gradients flow: OK')\n",
                "\n",
                "print()\n",
                "print('Test 2: Alpha scheduling')\n",
                "scheduler = AlphaScheduler(alpha_start=0.7, alpha_end=0.3, total_steps=10)\n",
                "alphas = []\n",
                "for i in range(12):\n",
                "    alphas.append(scheduler.get_alpha())\n",
                "    scheduler.step()\n",
                "print(f'  Alpha over 12 steps: {[f\"{a:.2f}\" for a in alphas]}')\n",
                "print(f'  Starts at 0.70, ends at 0.30: {alphas[0]:.2f} -> {alphas[-1]:.2f}')\n",
                "\n",
                "print()\n",
                "print('Test 3: BIO span extraction')\n",
                "test_bio = [0, 0, 1, 2, 0, 1, 0, 0]   # two aspects: (2,4) and (5,6)\n",
                "spans = extract_spans_from_bio(test_bio)\n",
                "print(f'  BIO: {test_bio}')\n",
                "print(f'  Extracted spans: {spans}')\n",
                "assert spans == [(2, 4), (5, 6)], f'Expected [(2,4), (5,6)], got {spans}'\n",
                "print('  Span extraction: OK')\n",
                "\n",
                "print()\n",
                "print('Test 4: Strict F1 computation')\n",
                "pred = [[0, 0, 1, 2, 0, 1, 0],    # spans: (2,4), (5,6)\n",
                "        [0, 1, 2, 2, 0, 0, 0]]     # spans: (1,4)\n",
                "gold = [[0, 0, 1, 2, 0, 0, 1],    # spans: (2,4), (6,7)\n",
                "        [0, 1, 2, 2, 0, 0, 0]]     # spans: (1,4)\n",
                "f1_result = compute_strict_f1(pred, gold)\n",
                "print(f'  Pred spans: (2,4),(5,6) and (1,4)')\n",
                "print(f'  Gold spans: (2,4),(6,7) and (1,4)')\n",
                "print(f'  Exact matches: 2 (out of 3 pred, 3 gold)')\n",
                "print(f'  P={f1_result[\"precision\"]:.4f}, R={f1_result[\"recall\"]:.4f}, F1={f1_result[\"f1\"]:.4f}')\n",
                "\n",
                "print()\n",
                "print('All unit tests passed.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Single-Batch Overfit Test\n",
                "\n",
                "Before full training, I verify the training loop is wired correctly by\n",
                "overfitting on a single batch for 50 iterations. If the loss drops to\n",
                "near zero, the forward/backward/optimizer pipeline works."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Building a small test dataloader for the overfit test\n",
                "preprocessor = ABSAPreprocessor(\n",
                "    model_name=config['model']['backbone'],\n",
                "    max_len=config['model']['max_len'],\n",
                ")\n",
                "\n",
                "overfit_df = pd.DataFrame([\n",
                "    {'sentence_id': '0001', 'sentence': 'The spicy ramen was incredibly delicious.',\n",
                "     'aspect': 'ramen', 'polarity': 'positive', 'span_start': 10, 'span_end': 15},\n",
                "    {'sentence_id': '0002', 'sentence': 'Bad service and rude staff.',\n",
                "     'aspect': 'service', 'polarity': 'negative', 'span_start': 4, 'span_end': 11},\n",
                "])\n",
                "\n",
                "label_map = config['labels']['polarity']\n",
                "overfit_loader = create_dataloader(overfit_df, preprocessor, label_map, batch_size=2, shuffle=False)\n",
                "overfit_batch = next(iter(overfit_loader))\n",
                "\n",
                "print(f'Overfit batch keys: {list(overfit_batch.keys())}')\n",
                "print(f'Batch size: {overfit_batch[\"input_ids\"].shape[0]}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Overfit on single batch on GPU\n",
                "torch.cuda.empty_cache()\n",
                "\n",
                "overfit_model = ModernBERT_RGAT(\n",
                "    model_name=config['model']['backbone'],\n",
                "    hidden_dim=config['model']['hidden_dim'],\n",
                "    num_sentiment_classes=config['model']['num_sentiment_classes'],\n",
                "    num_bio_tags=config['model']['num_bio_tags'],\n",
                "    num_relations=config['model']['rgat']['num_relations'],\n",
                "    rgat_dropout=config['model']['rgat']['dropout'],\n",
                ").to(device)\n",
                "\n",
                "overfit_loss_fn = JointTaskLoss(alpha_start=0.5, alpha_end=0.5, gamma=0.0, total_steps=50)\n",
                "overfit_optimizer = torch.optim.AdamW(overfit_model.parameters(), lr=5e-5)\n",
                "\n",
                "# Move batch to device\n",
                "batch_on_device = {k: v.to(device) for k, v in overfit_batch.items()}\n",
                "\n",
                "print(f'Starting overfit test on {device} (50 iterations on 1 batch)...')\n",
                "overfit_model.train()\n",
                "losses = []\n",
                "\n",
                "for step in range(50):\n",
                "    outputs = overfit_model(\n",
                "        input_ids=batch_on_device['input_ids'],\n",
                "        attention_mask=batch_on_device['attention_mask'],\n",
                "        adj_matrix=batch_on_device['adj_matrix'],\n",
                "        aspect_mask=batch_on_device['aspect_mask'],\n",
                "    )\n",
                "    total, ate, asc = overfit_loss_fn(\n",
                "        outputs['ate_logits'], batch_on_device['bio_labels'],\n",
                "        outputs['sentiment_logits'], batch_on_device['sentiment_label'],\n",
                "    )\n",
                "    \n",
                "    overfit_optimizer.zero_grad()\n",
                "    total.backward()\n",
                "    overfit_optimizer.step()\n",
                "    losses.append(total.item())\n",
                "    \n",
                "    if (step + 1) % 10 == 0:\n",
                "        print(f'  Step {step+1:3d}: loss={total.item():.4f} (ate={ate.item():.4f}, asc={asc.item():.4f})')\n",
                "\n",
                "print(f'\\nLoss dropped from {losses[0]:.4f} to {losses[-1]:.4f}')\n",
                "if losses[-1] < losses[0] * 0.5:\n",
                "    print('Overfit test PASSED -- loss decreased significantly.')\n",
                "else:\n",
                "    print('WARNING: Loss did not decrease enough. Check the training pipeline.')\n",
                "\n",
                "# Clean up to free GPU memory\n",
                "del overfit_model, overfit_optimizer, overfit_loss_fn, batch_on_device\n",
                "torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Train on SemEval 2014\n",
                "\n",
                "Full training run with early stopping and checkpointing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_on_dataset(config, year, preprocessor, device):\n",
                "    \"\"\"\n",
                "    Full training pipeline for one dataset year.\n",
                "    Returns the trainer object (for accessing history and metrics).\n",
                "    \"\"\"\n",
                "    label_map = config['labels']['polarity']\n",
                "    \n",
                "    # Load and split data\n",
                "    print(f'\\nLoading SemEval {year} data...')\n",
                "    train_df, val_df, test_df = build_splits(config, year, verbose=True)\n",
                "    print(f'  Train: {len(train_df)} rows, Val: {len(val_df)} rows, Test: {len(test_df)} rows')\n",
                "    \n",
                "    # Create dataloaders\n",
                "    train_loader = create_dataloader(\n",
                "        train_df, preprocessor, label_map,\n",
                "        batch_size=config['training']['batch_size'],\n",
                "        shuffle=True,\n",
                "    )\n",
                "    val_loader = create_dataloader(\n",
                "        val_df, preprocessor, label_map,\n",
                "        batch_size=config['training']['eval_batch_size'],\n",
                "        shuffle=False,\n",
                "    )\n",
                "    print(f'  Train batches: {len(train_loader)}, Val batches: {len(val_loader)}')\n",
                "    \n",
                "    # Compute class weights from training data\n",
                "    class_weights = compute_class_weights(train_df, label_map)\n",
                "    weight_tensor = torch.tensor(\n",
                "        [class_weights[i] for i in range(len(label_map))],\n",
                "        dtype=torch.float,\n",
                "    )\n",
                "    print(f'  Class weights: {class_weights}')\n",
                "    \n",
                "    # Clean GPU before loading model\n",
                "    torch.cuda.empty_cache()\n",
                "    \n",
                "    # Build fresh model\n",
                "    model = ModernBERT_RGAT(\n",
                "        model_name=config['model']['backbone'],\n",
                "        hidden_dim=config['model']['hidden_dim'],\n",
                "        num_sentiment_classes=config['model']['num_sentiment_classes'],\n",
                "        num_bio_tags=config['model']['num_bio_tags'],\n",
                "        num_relations=config['model']['rgat']['num_relations'],\n",
                "        rgat_dropout=config['model']['rgat']['dropout'],\n",
                "    )\n",
                "    \n",
                "    # Create trainer and run\n",
                "    trainer = Trainer(\n",
                "        model=model,\n",
                "        train_loader=train_loader,\n",
                "        val_loader=val_loader,\n",
                "        config=config,\n",
                "        sentiment_weights=weight_tensor,\n",
                "        device=device,\n",
                "        dataset_year=year,\n",
                "    )\n",
                "    \n",
                "    results = trainer.train()\n",
                "    \n",
                "    # Clean up after training to free GPU for next dataset\n",
                "    del trainer.model, trainer.optimizer, trainer.scaler\n",
                "    torch.cuda.empty_cache()\n",
                "    \n",
                "    return trainer, results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trainer_2014, results_2014 = train_on_dataset(config, '2014', preprocessor, device)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Train on SemEval 2015"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trainer_2015, results_2015 = train_on_dataset(config, '2015', preprocessor, device)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Train on SemEval 2016"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trainer_2016, results_2016 = train_on_dataset(config, '2016', preprocessor, device)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Training Curves"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_training_curves(results_dict):\n",
                "    \"\"\"Plot training curves for all datasets.\"\"\"\n",
                "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
                "    \n",
                "    for col, (year, results) in enumerate(results_dict.items()):\n",
                "        history = results['history']\n",
                "        epochs = range(1, len(history['train_loss']) + 1)\n",
                "        \n",
                "        # Top row: Loss curves\n",
                "        ax = axes[0, col]\n",
                "        ax.plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
                "        ax.plot(epochs, history['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
                "        ax.set_title(f'SemEval {year} - Loss', fontsize=13, fontweight='bold')\n",
                "        ax.set_xlabel('Epoch')\n",
                "        ax.set_ylabel('Loss')\n",
                "        ax.legend()\n",
                "        ax.grid(True, alpha=0.3)\n",
                "        \n",
                "        # Bottom row: F1 curves\n",
                "        ax = axes[1, col]\n",
                "        ax.plot(epochs, history['val_ate_f1'], 'g-', label='ATE F1 (Strict)', linewidth=2)\n",
                "        ax.plot(epochs, history['val_asc_f1'], 'm-', label='ASC F1 (Macro)', linewidth=2)\n",
                "        ax.plot(epochs, history['val_asc_accuracy'], 'c--', label='ASC Accuracy', linewidth=1.5)\n",
                "        ax.set_title(f'SemEval {year} - Validation Metrics', fontsize=13, fontweight='bold')\n",
                "        ax.set_xlabel('Epoch')\n",
                "        ax.set_ylabel('Score')\n",
                "        ax.legend()\n",
                "        ax.set_ylim(0, 1)\n",
                "        ax.grid(True, alpha=0.3)\n",
                "    \n",
                "    plt.suptitle('ModernBERT-RGAT Training Curves', fontsize=16, fontweight='bold', y=1.02)\n",
                "    plt.tight_layout()\n",
                "    \n",
                "    # Save the plot\n",
                "    os.makedirs('outputs/plots', exist_ok=True)\n",
                "    plt.savefig('outputs/plots/training_curves.png', dpi=150, bbox_inches='tight')\n",
                "    plt.show()\n",
                "    print('Training curves saved: outputs/plots/training_curves.png')\n",
                "\n",
                "all_results = {}\n",
                "if results_2014: all_results['2014'] = results_2014\n",
                "if results_2015: all_results['2015'] = results_2015\n",
                "if results_2016: all_results['2016'] = results_2016\n",
                "\n",
                "if all_results:\n",
                "    plot_training_curves(all_results)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Results Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compile final results table from all three training runs\n",
                "summary_rows = []\n",
                "\n",
                "for year, results in all_results.items():\n",
                "    best = results.get('best_val_metrics', {})\n",
                "    if best:\n",
                "        summary_rows.append({\n",
                "            'Dataset': f'SemEval {year}',\n",
                "            'ATE P': f\"{best.get('ate_precision', 0):.4f}\",\n",
                "            'ATE R': f\"{best.get('ate_recall', 0):.4f}\",\n",
                "            'ATE F1 (Strict)': f\"{best.get('ate_f1', 0):.4f}\",\n",
                "            'ASC Acc': f\"{best.get('asc_accuracy', 0):.4f}\",\n",
                "            'ASC F1 (Macro)': f\"{best.get('asc_f1', 0):.4f}\",\n",
                "            'Time (min)': f\"{results.get('total_time_seconds', 0)/60:.1f}\",\n",
                "        })\n",
                "\n",
                "if summary_rows:\n",
                "    summary_df = pd.DataFrame(summary_rows)\n",
                "    display(summary_df)\n",
                "    \n",
                "    # Save results\n",
                "    os.makedirs('outputs/results', exist_ok=True)\n",
                "    summary_df.to_csv('outputs/results/training_summary.csv', index=False)\n",
                "    print('\\nResults saved: outputs/results/training_summary.csv')\n",
                "else:\n",
                "    print('No training results available yet.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# RGAT relation weights after training (interpretability check)\n",
                "print('RGAT Relation Importance Weights (post-training):')\n",
                "print('='*50)\n",
                "\n",
                "for year, results in all_results.items():\n",
                "    checkpoint_path = os.path.join(config['training']['checkpoint_dir'], f'best_model_{year}.pt')\n",
                "    if os.path.exists(checkpoint_path):\n",
                "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
                "        # Extract relation importance from state dict\n",
                "        rel_names = ['nsubj', 'amod', 'obj', 'advmod', 'neg', 'compound', 'conj']\n",
                "        raw_weights = checkpoint['model_state_dict']['rgat.relation_importance']\n",
                "        weights = torch.sigmoid(raw_weights).tolist()\n",
                "        \n",
                "        print(f'\\n  SemEval {year}:')\n",
                "        sorted_rels = sorted(zip(rel_names, weights), key=lambda x: -x[1])\n",
                "        for name, w in sorted_rels:\n",
                "            bar = '#' * int(w * 30)\n",
                "            print(f'    {name:10s}: {w:.4f}  {bar}')\n",
                "\n",
                "print(f'\\n{\"=\"*50}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Phase 4 Summary\n",
                "\n",
                "| Component | Status |\n",
                "|-----------|--------|\n",
                "| JointTaskLoss (ATE CE + ASC Focal) | Done |\n",
                "| Dynamic alpha scheduling (0.7 -> 0.3) | Done |\n",
                "| Trainer with FP16 + gradient clipping | Done |\n",
                "| LR warmup + linear decay | Done |\n",
                "| Strict F1 (exact span match) | Done |\n",
                "| Early stopping (patience=5) | Done |\n",
                "| Checkpoint save/load | Done |\n",
                "| Training curves + results | Done |\n",
                "\n",
                "**Next step:** Phase 5 - Evaluation & Benchmarking"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}