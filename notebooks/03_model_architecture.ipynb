{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 03 - Model Architecture Validation\n",
                "\n",
                "Validating the ModernBERT-RGAT joint model architecture:\n",
                "\n",
                "1. Install dependencies and import modules\n",
                "2. Build the model from config\n",
                "3. Parameter count breakdown\n",
                "4. Smoke test forward pass with dummy data\n",
                "5. RGAT relation importance inspection\n",
                "6. BIO label alignment verification\n",
                "7. Full Dataset to DataLoader to Model pipeline test\n",
                "8. Adjacency tensor visualization\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Dependencies & Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Installing required packages that may not be present\n",
                "import subprocess, sys\n",
                "\n",
                "def install_if_missing(package, pip_name=None):\n",
                "    try:\n",
                "        __import__(package)\n",
                "    except ImportError:\n",
                "        print(f'Installing {pip_name or package}...')\n",
                "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pip_name or package])\n",
                "\n",
                "install_if_missing('torch', 'torch')\n",
                "install_if_missing('transformers', 'transformers')\n",
                "install_if_missing('spacy', 'spacy')\n",
                "install_if_missing('yaml', 'PyYAML')\n",
                "\n",
                "# Download spaCy English model if not present\n",
                "import spacy\n",
                "try:\n",
                "    spacy.load('en_core_web_sm')\n",
                "except OSError:\n",
                "    print('Downloading spaCy en_core_web_sm model...')\n",
                "    subprocess.check_call([sys.executable, '-m', 'spacy', 'download', 'en_core_web_sm'])\n",
                "\n",
                "print('All dependencies ready.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys, os\n",
                "\n",
                "# Set project root explicitly\n",
                "PROJECT_ROOT = os.path.expanduser('~/SOTA-ModernBERT-RGAT-Joint-Aspect-Sentiment-Extraction-for-Food-Tech-Reviews')\n",
                "assert os.path.isdir(PROJECT_ROOT), f'Project root not found: {PROJECT_ROOT}'\n",
                "\n",
                "if PROJECT_ROOT not in sys.path:\n",
                "    sys.path.insert(0, PROJECT_ROOT)\n",
                "os.chdir(PROJECT_ROOT)\n",
                "print(f'Project root: {PROJECT_ROOT}')\n",
                "\n",
                "import torch\n",
                "import pandas as pd\n",
                "\n",
                "from src.model import ModernBERT_RGAT, RGATLayer, ATEHead, ASCHead\n",
                "from src.dataset import ABSAPreprocessor, ABSADataset, create_dataloader\n",
                "from src.data_pipeline import load_config\n",
                "\n",
                "print(f'PyTorch: {torch.__version__}')\n",
                "print(f'CUDA available: {torch.cuda.is_available()}')\n",
                "if torch.cuda.is_available():\n",
                "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
                "\n",
                "print('Imports successful.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Config & Build Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "config_path = os.path.join(PROJECT_ROOT, 'configs', 'config.yaml')\n",
                "config = load_config(config_path)\n",
                "\n",
                "model = ModernBERT_RGAT(\n",
                "    model_name=config['model']['backbone'],\n",
                "    hidden_dim=config['model']['hidden_dim'],\n",
                "    num_sentiment_classes=config['model']['num_sentiment_classes'],\n",
                "    num_bio_tags=config['model']['num_bio_tags'],\n",
                "    num_relations=config['model']['rgat']['num_relations'],\n",
                "    rgat_dropout=config['model']['rgat']['dropout'],\n",
                ")\n",
                "\n",
                "print(f'Model built successfully.')\n",
                "print(f'  Backbone:   {config[\"model\"][\"backbone\"]}')\n",
                "print(f'  Max length: {config[\"model\"][\"max_len\"]}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Parameter Count Breakdown"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "param_counts = model.get_param_count()\n",
                "\n",
                "print('Parameter Count Breakdown:')\n",
                "print(f\"{'='*45}\")\n",
                "for component, count in param_counts.items():\n",
                "    print(f'  {component:15s}: {count:>12,}')\n",
                "print(f\"{'='*45}\")\n",
                "\n",
                "print(f\"\\nModernBERT backbone: ~{param_counts['bert']/1e6:.0f}M params\")\n",
                "print(f\"RGAT + task heads:   ~{(param_counts['total'] - param_counts['bert'])/1e3:.0f}K params\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Smoke Test: Forward Pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "max_len = config['model']['max_len']\n",
                "batch_size = 2\n",
                "num_relations = config['model']['rgat']['num_relations']\n",
                "\n",
                "# Dummy inputs to verify the forward pass works end-to-end\n",
                "dummy_input_ids = torch.randint(0, 1000, (batch_size, max_len))\n",
                "dummy_attention_mask = torch.ones(batch_size, max_len, dtype=torch.long)\n",
                "dummy_adj_matrix = torch.zeros(batch_size, num_relations, max_len, max_len)\n",
                "dummy_aspect_mask = torch.zeros(batch_size, max_len)\n",
                "dummy_aspect_mask[:, 3:5] = 1  # simulating aspect at token positions 3-4\n",
                "\n",
                "print('Running forward pass with dummy data...')\n",
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    outputs = model(\n",
                "        input_ids=dummy_input_ids,\n",
                "        attention_mask=dummy_attention_mask,\n",
                "        adj_matrix=dummy_adj_matrix,\n",
                "        aspect_mask=dummy_aspect_mask,\n",
                "    )\n",
                "\n",
                "print(f'\\nForward pass successful.')\n",
                "print(f'  ATE logits shape:       {outputs[\"ate_logits\"].shape}')      \n",
                "print(f'  Sentiment logits shape: {outputs[\"sentiment_logits\"].shape}')\n",
                "print(f'  Graph embeddings shape: {outputs[\"graph_embeddings\"].shape}')\n",
                "print(f'\\n  Expected ATE:       [{batch_size}, {max_len}, 3]')\n",
                "print(f'  Expected Sentiment: [{batch_size}, 4]')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. RGAT Relation Importance Weights (Initial)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Inspecting the learnable relation importance weights before training.\n",
                "# These should all start at the same value and diverge during training.\n",
                "\n",
                "rel_weights = model.get_relation_importance()\n",
                "\n",
                "print('RGAT Relation Importance Weights (pre-training):')\n",
                "print(f\"{'='*40}\")\n",
                "for rel, weight in rel_weights.items():\n",
                "    bar = '#' * int(weight * 30)\n",
                "    print(f'  {rel:10s}: {weight:.4f}  {bar}')\n",
                "print(f\"{'='*40}\")\n",
                "\n",
                "print('\\nAll weights start at sigmoid(1.0) = 0.7311.')\n",
                "print('After training, amod/neg/advmod should have higher weights.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. BIO Label Alignment Verification"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initializing the preprocessor with the same config the model uses\n",
                "preprocessor = ABSAPreprocessor(\n",
                "    model_name=config['model']['backbone'],\n",
                "    max_len=config['model']['max_len'],\n",
                ")\n",
                "\n",
                "# Testing BIO alignment on three cases:\n",
                "# single-word aspect, multi-word aspect, and implicit aspect\n",
                "test_cases = [\n",
                "    {\n",
                "        'text': 'The spicy ramen was incredibly delicious.',\n",
                "        'aspect': 'ramen',\n",
                "        'span_start': 10,\n",
                "        'span_end': 15,\n",
                "        'description': 'Single-word aspect'\n",
                "    },\n",
                "    {\n",
                "        'text': 'The delivery time was very fast.',\n",
                "        'aspect': 'delivery time',\n",
                "        'span_start': 4,\n",
                "        'span_end': 17,\n",
                "        'description': 'Multi-word aspect'\n",
                "    },\n",
                "    {\n",
                "        'text': 'Great food and excellent atmosphere.',\n",
                "        'aspect': '[ASPECT]',\n",
                "        'span_start': 0,\n",
                "        'span_end': 0,\n",
                "        'description': 'Implicit aspect'\n",
                "    },\n",
                "]\n",
                "\n",
                "label_names = {-100: 'IGN', 0: 'O', 1: 'B-ASP', 2: 'I-ASP'}\n",
                "\n",
                "for tc in test_cases:\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"Test: {tc['description']}\")\n",
                "    print(f\"Text: \\\"{tc['text']}\\\"\")\n",
                "    print(f\"Aspect: \\\"{tc['aspect']}\\\" [{tc['span_start']}:{tc['span_end']}]\")\n",
                "    \n",
                "    bio_labels, aspect_mask = preprocessor.align_bio_labels(\n",
                "        tc['text'], tc['aspect'], tc['span_start'], tc['span_end']\n",
                "    )\n",
                "    \n",
                "    # Decoding tokens for display\n",
                "    encoding = preprocessor.tokenizer(\n",
                "        tc['text'],\n",
                "        add_special_tokens=True,\n",
                "        truncation=True,\n",
                "        max_length=config['model']['max_len'],\n",
                "    )\n",
                "    tokens = preprocessor.tokenizer.convert_ids_to_tokens(encoding.input_ids)\n",
                "    \n",
                "    print(f\"\\n  {'Token':15s} {'BIO Label':10s} {'Aspect Mask':12s}\")\n",
                "    print(f\"  {'-'*40}\")\n",
                "    for i, tok in enumerate(tokens):\n",
                "        lbl = bio_labels[i].item()\n",
                "        msk = aspect_mask[i].item()\n",
                "        lbl_name = label_names.get(lbl, str(lbl))\n",
                "        marker = '  <--' if lbl in [1, 2] else ''\n",
                "        print(f'  {tok:15s} {lbl_name:10s} {msk:12.0f}{marker}')\n",
                "\n",
                "print(f\"\\n{'='*60}\")\n",
                "print('BIO alignment verification complete.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Dataset + DataLoader Integration Test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Building a small test DataFrame to verify the full pipeline\n",
                "test_df = pd.DataFrame([\n",
                "    {'sentence_id': '0001', 'sentence': 'The spicy ramen was incredibly delicious.',\n",
                "     'aspect': 'ramen', 'polarity': 'positive', 'span_start': 10, 'span_end': 15},\n",
                "    {'sentence_id': '0002', 'sentence': 'The delivery time was very fast.',\n",
                "     'aspect': 'delivery time', 'polarity': 'positive', 'span_start': 4, 'span_end': 17},\n",
                "    {'sentence_id': '0003', 'sentence': 'Bad service and rude staff.',\n",
                "     'aspect': 'service', 'polarity': 'negative', 'span_start': 4, 'span_end': 11},\n",
                "    {'sentence_id': '0004', 'sentence': 'Overall a decent place.',\n",
                "     'aspect': '[ASPECT]', 'polarity': 'neutral', 'span_start': 0, 'span_end': 0},\n",
                "])\n",
                "\n",
                "label_map = config['labels']['polarity']\n",
                "\n",
                "dataloader = create_dataloader(\n",
                "    df=test_df,\n",
                "    preprocessor=preprocessor,\n",
                "    label_map=label_map,\n",
                "    batch_size=2,\n",
                "    shuffle=False,\n",
                ")\n",
                "\n",
                "print(f'DataLoader created: {len(dataloader)} batches\\n')\n",
                "\n",
                "for batch_idx, batch in enumerate(dataloader):\n",
                "    print(f'Batch {batch_idx + 1}:')\n",
                "    for key, val in batch.items():\n",
                "        print(f'  {key:18s}: shape={str(val.shape):20s}  dtype={val.dtype}')\n",
                "    \n",
                "    # Running forward pass through the model\n",
                "    model.eval()\n",
                "    with torch.no_grad():\n",
                "        outputs = model(\n",
                "            input_ids=batch['input_ids'],\n",
                "            attention_mask=batch['attention_mask'],\n",
                "            adj_matrix=batch['adj_matrix'],\n",
                "            aspect_mask=batch['aspect_mask'],\n",
                "        )\n",
                "    print(f'  > ATE logits:       {outputs[\"ate_logits\"].shape}')\n",
                "    print(f'  > Sentiment logits: {outputs[\"sentiment_logits\"].shape}')\n",
                "    print()\n",
                "\n",
                "print('Full pipeline test passed: DataFrame -> Dataset -> DataLoader -> Model')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Adjacency Tensor Inspection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "test_text = 'The spicy ramen was incredibly delicious.'\n",
                "adj = preprocessor.build_adjacency_tensor(test_text)\n",
                "\n",
                "# Getting tokens for axis labels\n",
                "enc = preprocessor.tokenizer(test_text, add_special_tokens=True, truncation=True, max_length=config['model']['max_len'])\n",
                "tokens = preprocessor.tokenizer.convert_ids_to_tokens(enc.input_ids)\n",
                "n_tokens = len(tokens)\n",
                "\n",
                "rel_names = ['nsubj', 'amod', 'obj', 'advmod', 'neg', 'compound', 'conj']\n",
                "\n",
                "# Filtering to only show relations that have edges in this sentence\n",
                "active_rels = [(i, name) for i, name in enumerate(rel_names) if adj[i, :n_tokens, :n_tokens].sum() > 0]\n",
                "\n",
                "if active_rels:\n",
                "    fig, axes = plt.subplots(1, len(active_rels), figsize=(5*len(active_rels), 4))\n",
                "    if len(active_rels) == 1:\n",
                "        axes = [axes]\n",
                "    \n",
                "    for ax, (rel_idx, rel_name) in zip(axes, active_rels):\n",
                "        mat = adj[rel_idx, :n_tokens, :n_tokens].numpy()\n",
                "        sns.heatmap(mat, xticklabels=tokens, yticklabels=tokens, \n",
                "                    cmap='Blues', ax=ax, square=True, cbar=False)\n",
                "        ax.set_title(f'{rel_name} ({rel_idx})', fontsize=11, fontweight='bold')\n",
                "        ax.tick_params(axis='both', labelsize=8)\n",
                "    \n",
                "    plt.suptitle(f'Dependency Relations: \\\"{test_text}\\\"', fontsize=13, fontweight='bold', y=1.02)\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "else:\n",
                "    print('No active dependency relations found for this sentence.')\n",
                "\n",
                "print(f'\\nAdjacency tensor shape: {adj.shape}')\n",
                "print(f'Non-zero edges: {(adj > 0).sum().item()}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Phase 3 Summary\n",
                "\n",
                "| Component | Status |\n",
                "|-----------|--------|\n",
                "| RGATLayer with learnable relation weights | Done |\n",
                "| ATEHead - BIO tagger | Done |\n",
                "| ASCHead - CLS + MaxPool | Done |\n",
                "| ModernBERT_RGAT joint forward | Done |\n",
                "| Sub-word alignment (-100) | Done |\n",
                "| ABSADataset + DataLoader | Done |\n",
                "| Forward pass smoke test | Done |\n",
                "| Adjacency tensor visualization | Done |\n",
                "\n",
                "**Next step:** Phase 4 - Training Engine"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}